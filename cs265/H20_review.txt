what is the problem

1. Databases are designed off one type of decisions
2. But same choice is not suitable for all workloads and requirements

why is it important
1. to get the best performance each problem needs a different approach.

why is it hard:

- Defining all possible permutations and combinations of the layout and choosing the most optimal
  solution is NP hard
- In practice its not feasible to do this for all tables with many attributes.
- Proper hueristics techniques need to be applied to prune/limit the search space without impacting the quality.

why existing solutions do not work

- The way data is stored - defines the maximum performance as it defines how much data must be
accessed for query
- Traditional row database - store data row wise
- Modern column store - stores column at a time
- Neither of these are alone a good solution for all use cases.
- Database vendors - provide different engines in same software ( MySql has - MyISAM, InnoDB)
- commuincation between different data engines/parts is not possible
- Each engine has knowledge to know how best to access data



what is the core intuition for the solution

2 main ideas
-  Flexible storage layout.
- Design dynamically choosen based on the data /queries
- Data layouts combined with proper execution strategies.


solution step by step

- H20 is an adaptive Hybrid System - that (re)defines the layout dynamically based on the workload.
- Row based
    - more suited for transaction (OLTP) based application- and have data orgainzed in sequential pages
    - optimized for write intensive workload.
    - when only some attributes are needed by a query - overhead
    - Volcano style data processing - data is processed one tuple/row at a time
     -- leads to instruction and cache misses
     -- no materialization cost.

- Column store
  -- optimal for analytical queries - OLAP
  -- DSM ( decomposition Storage Model) - data stored in columns and processed column at a time


-  Architecture of H20
  - DataLayout Manager - responsible for maintaining and creating different layouts
  - Query Processor - evalutes alternate processes plans for the query based on the layouts
  - Operator Generator - generates query operators based on the chosen layout and plan
  - Adaptation mechanism - periodially invoked to evalues layouts and propose new ones to Layout manager

- Supported Layouts
   - 3 types
    1. Row-major - tuple sequentially in pages
    2. Column-major - individual columns
    3. Grouped-columns - Combined a group of attributes of the original relation.

- Continuous Adaptation
  - dynamic workload
  -  One approach would be to trigger datalayout one every query
   -- but this is only useful if the cost can be amortized over furture queries
  -- H20 gathers statistics of the queries. and the history of recent queries - triggeres adapation
  -- this trigger will evaluate the benefit from a new layout and selects te most fitting solution

- Monitoring :

   - USes a window of N-queries to monitor the access patterns.
   - Window also adapts to statics - not static
   - the window size defines how aggresives/conservative H20 is.
   - It defines the number of queries in history that will trigger an adaptation mechanism
   - It looks at the attribute queried and the frequency of attributes accessed together
   - The access patterns are stored in 2*2 matrics - where , select clauses
   - affinity - expresses the extent to which the attributes are accessed together
   - having this information in 2-views - helps with defining the optimal layout for query and access pattern


 Solution:

  - H20 starts with the attributes accessed by queries to generate potential layouts
  - initial configuration contains the narrowest possible groups of columns
  - when narrow group of columns is accessed by the query - all columns are accessed
  - The algorithm then progresively improves the proposed soln by considering the new groups of columns
  -  new groups generated by merging new groups with narrow groups of previous
  - generation and selection continued until no further selection is possible

 - H20 considers the cost of transforming to the new layout - to ensure the cost can be amortized.

- combines data reorganization with query processing in order to reduce the time query has to wait before starting to process.
 - early materialization - helps to generate layout + query -> no cost of scanning twice

 Oscillating workloads:
   - should detect workload and avoid temporary changes
   - workload shift detected by comparing new queries with queries in previous query window

Execution Strategies:
 - Vectorized processing
 - Vector fit in L1 cache
 - Row major
  - Volcano style data processing - data is processed one tuple/row at a time
  - Early tuple filtering - Predicate evalution pushed down to scan operator
 - Column major
  - materializes intermediate results from filter evaluations
into vectors of matching positions
- Groups of columns
 - NO fixed strategy
 - selects dynamically

 Creating Operators:
  - generated dynamic operators to reduce interpretation overhead  and to combine
  workload specific data layouts


does the paper prove its claims

exact setup of analysis/experiments

are there any gaps in the logic/proof

possible next steps